{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SER_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNF+kIFV5yDvaCyZ6MWJnU9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iasonaspg/ser-repo/blob/main/SER_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztKpweeFnHW6"
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb\r\n",
        "!ls  # Check if required cuda 9.0 amd64-deb file is downloaded\r\n",
        "!dpkg -i cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb\r\n",
        "!ls /var/cuda-repo-9-0-local | grep .pub\r\n",
        "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\r\n",
        "!apt-get update\r\n",
        "!sudo apt-get install cuda-9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt_3_63bo1mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ac9dbd-6e2f-4aba-fff3-54194a705cc3"
      },
      "source": [
        "!pip install thundersvm"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: thundersvm in /usr/local/lib/python3.7/dist-packages (0.3.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from thundersvm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from thundersvm) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from thundersvm) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->thundersvm) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YyhdsAjCDnZ",
        "outputId": "095c7c96-f5c1-4451-f846-cead7690a3f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzYtHFdnDwWM"
      },
      "source": [
        "!python -m pip install -U pip\n",
        "!pip uninstall librosa\n",
        "!pip install librosa\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio, display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U9Y8_lvNdH9",
        "outputId": "c5e6667b-edae-4af9-ca1f-32fc3e57d1d9"
      },
      "source": [
        "print(librosa.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FnGuGZJDOb0",
        "outputId": "f17a408e-99d2-4d79-b62c-c26442aba7ea"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Emotions/')\n",
        "!ls "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anger\t\t\t\t\t\t      fear\n",
            "Br_CSV\t\t\t\t\t\t      feature_test_vector.csv\n",
            "cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb    feature_train_vector.csv\n",
            "cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64-deb.1  happiness\n",
            "disgust\t\t\t\t\t\t      sadness\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpM1p_TvIzm-"
      },
      "source": [
        "# load audio files\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# define STFT global parameters\n",
        "fs = 22050\n",
        "n_fft, hop = 1024, 256\n",
        "\n",
        "# Fucntions require you to be in the root data directory\n",
        "def get_train_wav_dir(dir_name,fs=44100):\n",
        "  return [ librosa.load(p,fs)[0] for p in Path().glob('./' + dir_name + '/train' + '/*.wav') ]\n",
        "\n",
        "def get_test_wav_dir(dir_name,fs=44100):\n",
        "  return [ librosa.load(p,fs)[0] for p in Path().glob('./' + dir_name + '/test' + '/*.wav') ]\n",
        "\n",
        "\n",
        "\n",
        "emotions = [\"sadness\",\"happiness\",\"anger\",\"fear\",\"disgust\"]\n",
        "\n",
        "# list of len(emotions) that contains lists of numpy arrays. Each numpy array belongs to a single wav file\n",
        "train_wav = []\n",
        "test_wav = []\n",
        "for emotion in emotions:\n",
        "  train_wav.append(get_train_wav_dir(emotion,fs))\n",
        "  test_wav.append(get_test_wav_dir(emotion,fs))\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVbiwoMCBreL",
        "outputId": "ed020c05-900a-4b05-b6cf-3387d10a3938"
      },
      "source": [
        "# Read brightness extracted features that were saved in csv files\n",
        "\n",
        "from numpy import genfromtxt\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Emotions/Br_CSV/')\n",
        "\n",
        "# Create two lists that contain len(emotions) numpy arrays. Each row of the arrays represents the brightness x% of an entire emotion for the total of the emotion wav files, divided in frames\n",
        "br_train = []\n",
        "br_test = []\n",
        "for emotion in emotions:\n",
        "  filename = 'br_' + emotion + '_train.csv'\n",
        "  temp = genfromtxt(filename,delimiter=',')\n",
        "  np.nan_to_num(temp,copy=False)\n",
        "  br_train.append(temp)\n",
        "  filename = 'br_' + emotion + '_test.csv'\n",
        "  temp = genfromtxt(filename,delimiter=',')\n",
        "  np.nan_to_num(temp,copy=False)\n",
        "  br_test.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "print(br_train[0].shape)\n",
        "print(br_train[1].shape)\n",
        "print(br_train[2].shape)\n",
        "print(br_train[3].shape)\n",
        "print(br_train[4].shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 32013)\n",
            "(2, 28208)\n",
            "(2, 25665)\n",
            "(2, 27131)\n",
            "(2, 34553)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2GE7RSiQLXd",
        "outputId": "a66a97b2-7ded-480f-9bc0-c6c758e6e777"
      },
      "source": [
        "# Feature extraction of audio files\n",
        "\n",
        "from librosa.feature import spectral\n",
        "\n",
        "# Gets a list of wav signals and returns a numpy array of features x nFrames_total and a list of len(input) containing the nFrames per signal\n",
        "def extract_features(wav):\n",
        "  spectral_centroid = spectral.spectral_centroid(wav[0], sr=fs, n_fft=n_fft, hop_length=hop, center=False)\n",
        "  spectral_rolloff = spectral.spectral_rolloff(wav[0], sr=fs, n_fft=n_fft, hop_length=hop,roll_percent=0.30, center=False)\n",
        "  spectral_rolloff50 = spectral.spectral_rolloff(wav[0], sr=fs, n_fft=n_fft, hop_length=hop,roll_percent=0.50, center=False)\n",
        "  zero_crossing_rate = spectral.zero_crossing_rate(wav[0], frame_length=n_fft, hop_length=hop, center=False)\n",
        "\n",
        "  mfcc = librosa.feature.mfcc(wav[0], sr=fs, n_fft=n_fft, hop_length=hop, n_mfcc=7, center=False)\n",
        "  desired_mfcc = np.concatenate((mfcc[1:2,:],mfcc[3:5,:],mfcc[6:7,:]),axis=0)\n",
        "  rms = librosa.feature.rms(wav[0],frame_length=n_fft,hop_length=hop,center=False)\n",
        "  # mfcc_delta = librosa.feature.delta(desired_mfcc, order=1, mode='nearest')\n",
        "  # mfcc_delta2 = librosa.feature.delta(desired_mfcc, order=2, mode='nearest')\n",
        "  feature_vector = np.concatenate((spectral_centroid,spectral_rolloff,spectral_rolloff50,zero_crossing_rate,desired_mfcc,rms),axis=0)\n",
        "  nFrames = [0 for i in range(len(wav))]\n",
        "  nFrames[0] = spectral_centroid.shape[1]\n",
        "  for i in range(1,len(wav)):\n",
        "    cols = wav[i].shape[0]\n",
        "    spectral_centroid = spectral.spectral_centroid(wav[i], sr=fs, n_fft=n_fft, hop_length=hop, center=False)\n",
        "    spectral_rolloff = spectral.spectral_rolloff(wav[i], sr=fs, n_fft=n_fft, hop_length=hop,roll_percent=0.30, center=False)\n",
        "    spectral_rolloff50 = spectral.spectral_rolloff(wav[i], sr=fs, n_fft=n_fft, hop_length=hop,roll_percent=0.50, center=False)\n",
        "\n",
        "    zero_crossing_rate = spectral.zero_crossing_rate(wav[i], frame_length=n_fft, hop_length=hop, center=False)\n",
        "    mfcc = librosa.feature.mfcc(wav[i], sr=fs, n_fft=n_fft, hop_length=hop, n_mfcc=7, center=False)\n",
        "    desired_mfcc = np.concatenate((mfcc[1:2,:],mfcc[3:5,:],mfcc[6:7,:]),axis=0)\n",
        "    rms = librosa.feature.rms(wav[i],frame_length=n_fft,hop_length=hop,center=False)\n",
        "    # mfcc_delta = librosa.feature.delta(desired_mfcc, order=1, mode='nearest')\n",
        "    # mfcc_delta2 = librosa.feature.delta(desired_mfcc, order=2, mode='nearest')\n",
        "    feature_vector1 = np.concatenate((spectral_centroid,spectral_rolloff,spectral_rolloff50,zero_crossing_rate,desired_mfcc,rms),axis=0)\n",
        "    feature_vector = np.concatenate((feature_vector,feature_vector1),axis=1)\n",
        "    nFrames[i] = spectral_centroid.shape[1]\n",
        "  return feature_vector, nFrames\n",
        "\n",
        "# Create the feature matrix while working emotion by emotion. In each loop all the samples of the same emotion are used for feature extraction\n",
        "test_nframes = []\n",
        "train_nframes = []\n",
        "feature_train_vector, _ = extract_features(train_wav[0])\n",
        "label_vec = [0 for i in range(feature_train_vector.shape[1])]\n",
        "feature_train_vector = np.concatenate((feature_train_vector,br_train[0],np.array([label_vec])),axis=0)\n",
        "\n",
        "feature_test_vector, test_nframe = extract_features(test_wav[0])\n",
        "label_vec = [0 for i in range(feature_test_vector.shape[1])]\n",
        "feature_test_vector = np.concatenate((feature_test_vector,br_test[0],np.array([label_vec])),axis=0)\n",
        "test_nframes.append(test_nframe)\n",
        "for i in range(1,len(train_wav)):\n",
        "  train_feat_vec, train_nframe = extract_features(train_wav[i])\n",
        "  train_nframes.append(train_nframe)\n",
        "  label_vec = [i for j in range(train_feat_vec.shape[1])]\n",
        "  train_feat_vec = np.concatenate((train_feat_vec,br_train[i],np.array([label_vec])),axis=0)\n",
        "  feature_train_vector = np.concatenate((feature_train_vector,train_feat_vec),axis=1)\n",
        "\n",
        "  \n",
        "  test_feat_vec, test_nframe = extract_features(test_wav[i])\n",
        "  test_nframes.append(test_nframe)\n",
        "  label_vec = [i for j in range(test_feat_vec.shape[1])]\n",
        "  test_feat_vec = np.concatenate((test_feat_vec,br_test[i],np.array([label_vec])),axis=0)\n",
        "  feature_test_vector = np.concatenate((feature_test_vector,test_feat_vec),axis=1)\n",
        "\n",
        "\n",
        "print(feature_test_vector.shape)\n",
        "#print(happy_train_feat_vec.shape)\n",
        "print('=')\n",
        "print(feature_train_vector.shape)\n",
        "#print(feature_vector[:,0:2])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12, 25205)\n",
            "=\n",
            "(12, 147570)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ330dm4J4Xo"
      },
      "source": [
        "# Create some spectrograms\r\n",
        "import librosa.display\r\n",
        "os.chdir('/content/drive/My Drive/Emotions/')\r\n",
        "y,_ = librosa.load(\"./sadness/train/trimmed_s01 (6).wav\",fs)\r\n",
        "y1,_ = librosa.load(\"./happiness/train/trimmed_h01 (6).wav\",fs)\r\n",
        "\r\n",
        "# gets wav time series as nparray and emotion name as string and creates a spectrogram\r\n",
        "def get_spectr(wav,em):\r\n",
        "  S, phase = librosa.magphase(librosa.stft(y=wav, n_fft=n_fft, hop_length=hop, center=False))\r\n",
        "  print(S.shape)\r\n",
        "  cent = spectral.spectral_centroid(S=S)\r\n",
        "  rol30 = spectral.spectral_rolloff(S=S, sr=fs,roll_percent=0.30)\r\n",
        "  rol50 = spectral.spectral_rolloff(S=S, sr=fs,roll_percent=0.50)\r\n",
        "\r\n",
        "  times = librosa.times_like(cent)\r\n",
        "  times30 = librosa.times_like(rol30)\r\n",
        "  times50 = librosa.times_like(rol50)\r\n",
        "  fig, ax = plt.subplots(figsize=(10,7))\r\n",
        "  img = librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.min), y_axis='log', x_axis='time', ax=ax)\r\n",
        "  ax.plot(times, cent.T, label='Spectral centroid', color='w')\r\n",
        "  ax.plot(times30, rol30.T, label='Spectral rolloff 30', color='#95eddf')\r\n",
        "  ax.plot(times50, rol50.T, label='Spectral rolloff 50', color='b')\r\n",
        "  fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\r\n",
        "  ax.legend(loc='upper right')\r\n",
        "  ax.set(title= em + ' log Power spectrogram')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "get_spectr(y,\"sad\")\r\n",
        "get_spectr(y1,\"happy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9tITojZozbET",
        "outputId": "bc226fd4-72bf-49df-940a-9e818d945743"
      },
      "source": [
        "# Statistical description of data\n",
        "import pandas as pd\n",
        "feat_train = feature_train_vector[0:11,:].T\n",
        "\n",
        "pd_feat_train = pd.DataFrame(feat_train)\n",
        "pd_feat_train.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "      <td>147570.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2466.849859</td>\n",
              "      <td>1094.105888</td>\n",
              "      <td>1796.321196</td>\n",
              "      <td>0.135340</td>\n",
              "      <td>69.904337</td>\n",
              "      <td>8.923558</td>\n",
              "      <td>-5.913831</td>\n",
              "      <td>-12.793342</td>\n",
              "      <td>0.074399</td>\n",
              "      <td>0.840143</td>\n",
              "      <td>0.667034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1568.838165</td>\n",
              "      <td>1447.979581</td>\n",
              "      <td>1888.746918</td>\n",
              "      <td>0.147026</td>\n",
              "      <td>63.951290</td>\n",
              "      <td>29.482764</td>\n",
              "      <td>27.270888</td>\n",
              "      <td>20.128150</td>\n",
              "      <td>0.060985</td>\n",
              "      <td>0.199235</td>\n",
              "      <td>0.237168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>26.587444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-235.525085</td>\n",
              "      <td>-107.764870</td>\n",
              "      <td>-149.226013</td>\n",
              "      <td>-100.508789</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1408.982815</td>\n",
              "      <td>322.998047</td>\n",
              "      <td>538.330078</td>\n",
              "      <td>0.045898</td>\n",
              "      <td>37.315628</td>\n",
              "      <td>-10.931899</td>\n",
              "      <td>-22.989209</td>\n",
              "      <td>-25.982828</td>\n",
              "      <td>0.025422</td>\n",
              "      <td>0.775510</td>\n",
              "      <td>0.512320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1956.965492</td>\n",
              "      <td>495.263672</td>\n",
              "      <td>990.527344</td>\n",
              "      <td>0.076172</td>\n",
              "      <td>79.371826</td>\n",
              "      <td>7.661649</td>\n",
              "      <td>-5.786995</td>\n",
              "      <td>-11.890461</td>\n",
              "      <td>0.061680</td>\n",
              "      <td>0.907740</td>\n",
              "      <td>0.697565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2956.028462</td>\n",
              "      <td>968.994141</td>\n",
              "      <td>2217.919922</td>\n",
              "      <td>0.150391</td>\n",
              "      <td>113.570723</td>\n",
              "      <td>27.577981</td>\n",
              "      <td>11.082222</td>\n",
              "      <td>1.120398</td>\n",
              "      <td>0.108945</td>\n",
              "      <td>0.980080</td>\n",
              "      <td>0.864457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>8398.838795</td>\n",
              "      <td>8161.083984</td>\n",
              "      <td>9259.277344</td>\n",
              "      <td>0.805664</td>\n",
              "      <td>251.672791</td>\n",
              "      <td>170.622467</td>\n",
              "      <td>115.711357</td>\n",
              "      <td>81.680939</td>\n",
              "      <td>0.427108</td>\n",
              "      <td>0.999950</td>\n",
              "      <td>0.999920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0              1   ...             9              10\n",
              "count  147570.000000  147570.000000  ...  147570.000000  147570.000000\n",
              "mean     2466.849859    1094.105888  ...       0.840143       0.667034\n",
              "std      1568.838165    1447.979581  ...       0.199235       0.237168\n",
              "min        26.587444       0.000000  ...       0.000000       0.000000\n",
              "25%      1408.982815     322.998047  ...       0.775510       0.512320\n",
              "50%      1956.965492     495.263672  ...       0.907740       0.697565\n",
              "75%      2956.028462     968.994141  ...       0.980080       0.864457\n",
              "max      8398.838795    8161.083984  ...       0.999950       0.999920\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w4O0CI8XZVe"
      },
      "source": [
        "# Save features as csv file\n",
        "a = np.asarray(feature_train_vector)\n",
        "np.savetxt(\"feature_train_vector.csv\", a, delimiter=\",\")\n",
        "\n",
        "a = np.asarray(feature_test_vector)\n",
        "np.savetxt(\"feature_test_vector.csv\", a, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVl-zEedS1Fn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "b642d8c0-4fdf-4bb6-b170-334b0830bedb"
      },
      "source": [
        "# Normalize, standardize and conduct PCA\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "X_train = feat_train\n",
        "Y_train = feature_train_vector[11,:].T\n",
        "\n",
        "X_test = feature_test_vector[0:11,:].T\n",
        "Y_test = feature_test_vector[11,:].T\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "scaler = Normalizer()\n",
        "scaler.fit(X_train)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "pd_feat_train_norm = pd.DataFrame(X_train_norm)\n",
        "\n",
        "pca = decomposition.PCA(n_components=11)\n",
        "pca_train = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "pd_feat_train_scal = pd.DataFrame(X_train_scaled)\n",
        "pd_feat_train_scal.describe()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.475700e+05</td>\n",
              "      <td>1.475700e+05</td>\n",
              "      <td>1.475700e+05</td>\n",
              "      <td>1.475700e+05</td>\n",
              "      <td>1.475700e+05</td>\n",
              "      <td>1.475700e+05</td>\n",
              "      <td>1.475700e+05</td>\n",
              "      <td>1.475700e+05</td>\n",
              "      <td>1.475700e+05</td>\n",
              "      <td>1.475700e+05</td>\n",
              "      <td>1.475700e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-2.869991e-16</td>\n",
              "      <td>-6.434622e-16</td>\n",
              "      <td>4.729865e-16</td>\n",
              "      <td>-5.696105e-16</td>\n",
              "      <td>-5.230951e-16</td>\n",
              "      <td>-8.887807e-16</td>\n",
              "      <td>-7.677087e-17</td>\n",
              "      <td>-8.388868e-16</td>\n",
              "      <td>-9.458826e-17</td>\n",
              "      <td>-1.869193e-15</td>\n",
              "      <td>-4.689240e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000003e+00</td>\n",
              "      <td>1.000003e+00</td>\n",
              "      <td>1.000003e+00</td>\n",
              "      <td>1.000003e+00</td>\n",
              "      <td>1.000003e+00</td>\n",
              "      <td>1.000003e+00</td>\n",
              "      <td>1.000003e+00</td>\n",
              "      <td>1.000003e+00</td>\n",
              "      <td>1.000003e+00</td>\n",
              "      <td>1.000003e+00</td>\n",
              "      <td>1.000003e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.555464e+00</td>\n",
              "      <td>-7.556112e-01</td>\n",
              "      <td>-9.510683e-01</td>\n",
              "      <td>-9.205255e-01</td>\n",
              "      <td>-4.775986e+00</td>\n",
              "      <td>-3.957866e+00</td>\n",
              "      <td>-5.255152e+00</td>\n",
              "      <td>-4.357864e+00</td>\n",
              "      <td>-1.218636e+00</td>\n",
              "      <td>-4.216850e+00</td>\n",
              "      <td>-2.812513e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-6.743019e-01</td>\n",
              "      <td>-5.325424e-01</td>\n",
              "      <td>-6.660476e-01</td>\n",
              "      <td>-6.083447e-01</td>\n",
              "      <td>-5.095881e-01</td>\n",
              "      <td>-6.734621e-01</td>\n",
              "      <td>-6.261415e-01</td>\n",
              "      <td>-6.552779e-01</td>\n",
              "      <td>-8.031023e-01</td>\n",
              "      <td>-3.244069e-01</td>\n",
              "      <td>-6.523449e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-3.250087e-01</td>\n",
              "      <td>-4.135723e-01</td>\n",
              "      <td>-4.266303e-01</td>\n",
              "      <td>-4.024382e-01</td>\n",
              "      <td>1.480427e-01</td>\n",
              "      <td>-4.280175e-02</td>\n",
              "      <td>4.650964e-03</td>\n",
              "      <td>4.485676e-02</td>\n",
              "      <td>-2.085652e-01</td>\n",
              "      <td>3.392825e-01</td>\n",
              "      <td>1.287302e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.118105e-01</td>\n",
              "      <td>-8.640465e-02</td>\n",
              "      <td>2.232169e-01</td>\n",
              "      <td>1.023648e-01</td>\n",
              "      <td>6.828093e-01</td>\n",
              "      <td>6.327251e-01</td>\n",
              "      <td>6.232327e-01</td>\n",
              "      <td>6.912601e-01</td>\n",
              "      <td>5.664651e-01</td>\n",
              "      <td>7.023717e-01</td>\n",
              "      <td>8.324229e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.781148e+00</td>\n",
              "      <td>4.880595e+00</td>\n",
              "      <td>3.951287e+00</td>\n",
              "      <td>4.559244e+00</td>\n",
              "      <td>2.842305e+00</td>\n",
              "      <td>5.484542e+00</td>\n",
              "      <td>4.459906e+00</td>\n",
              "      <td>4.693655e+00</td>\n",
              "      <td>5.783569e+00</td>\n",
              "      <td>8.021033e-01</td>\n",
              "      <td>1.403593e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0             1   ...            9             10\n",
              "count  1.475700e+05  1.475700e+05  ...  1.475700e+05  1.475700e+05\n",
              "mean  -2.869991e-16 -6.434622e-16  ... -1.869193e-15 -4.689240e-15\n",
              "std    1.000003e+00  1.000003e+00  ...  1.000003e+00  1.000003e+00\n",
              "min   -1.555464e+00 -7.556112e-01  ... -4.216850e+00 -2.812513e+00\n",
              "25%   -6.743019e-01 -5.325424e-01  ... -3.244069e-01 -6.523449e-01\n",
              "50%   -3.250087e-01 -4.135723e-01  ...  3.392825e-01  1.287302e-01\n",
              "75%    3.118105e-01 -8.640465e-02  ...  7.023717e-01  8.324229e-01\n",
              "max    3.781148e+00  4.880595e+00  ...  8.021033e-01  1.403593e+00\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1NLMr25kajp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3590c6a-3dea-4ada-a06d-7f196f6eba22"
      },
      "source": [
        "# Print explained variance\n",
        "\n",
        "print(pca.explained_variance_ratio_,\"\\n\")\n",
        "#print(pca.explained_variance_)\n",
        "print(abs( pca.components_ )[0],\"\\n\")\n",
        "print(abs( pca.components_ )[1],\"\\n\")\n",
        "print(abs( pca.components_ )[2],\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.45840578 0.18285486 0.10734736 0.08733904 0.07297653 0.04679342\n",
            " 0.01788306 0.01146488 0.00714047 0.00568712 0.00210748] \n",
            "\n",
            "[0.43135714 0.41790639 0.42857404 0.4202851  0.39750623 0.03552982\n",
            " 0.07027021 0.0510116  0.1106557  0.18163777 0.25868778] \n",
            "\n",
            "[0.10097535 0.05969985 0.08862746 0.08859157 0.10942133 0.43934074\n",
            " 0.43077967 0.15283736 0.34541637 0.49820341 0.43484918] \n",
            "\n",
            "[0.03662048 0.10306708 0.05314632 0.10428999 0.03417959 0.38416389\n",
            " 0.52940227 0.62420826 0.08425853 0.32375252 0.20920597] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1PYlTJFqOri"
      },
      "source": [
        "# Use thundersvm SVM\r\n",
        "from joblib import dump\r\n",
        "from thundersvm import SVC\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "import time\r\n",
        "\r\n",
        "#clf = SVC(C=15.0,gamma=5.0,kernel='rbf')\r\n",
        "#clf.fit(X_train_scaled, Y_train)\r\n",
        "\r\n",
        "parameters = {'kernel':['rbf'], 'C':[1, 10, 20, 30], 'gamma':['auto',0.1,1,5,10]}\r\n",
        "svc = SVC()\r\n",
        "clf = GridSearchCV(svc, parameters)\r\n",
        "str = time.time()\r\n",
        "clf.fit(X_train_scaled, Y_train)\r\n",
        "print(time.time()-str)\r\n",
        "\r\n",
        "# dump(clf, './svm_gridsearch.joblib') \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9ax6QAF430X"
      },
      "source": [
        "clf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dyXIdmmRDBT"
      },
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "clf = load('./svm_gridsearch.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKCKi0wUdfVW"
      },
      "source": [
        "# Use libsvm and save the model\n",
        "from joblib import dump, load\n",
        "from sklearn import svm\n",
        "import time\n",
        "\n",
        "clf = svm.SVC(C=10.0)\n",
        "str = time.time()\n",
        "clf.fit(X_train_scaled, Y_train)\n",
        "print(time.time()-str)\n",
        "\n",
        "dump(clf, './svm_c10.joblib') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vbQmH5PR85Q"
      },
      "source": [
        "# Classification report using the mode(label) for each wav file\n",
        "from sklearn import metrics\n",
        "from statistics import mode, mean\n",
        "\n",
        "def acc_mode(clf,X_test):\n",
        "  accuracy_list = []\n",
        "  y_pred = []\n",
        "  y_true = []\n",
        "\n",
        "  i = 0\n",
        "  label = 0\n",
        "  for k in test_nframes:\n",
        "    for j in k:\n",
        "      pred = clf.predict(X_test[i:i+j,:])\n",
        "      try:\n",
        "        val = mode(pred)\n",
        "      except:\n",
        "        val = round(mean(pred))\n",
        "      y_pred.append(val)\n",
        "      y_true.append(label)\n",
        "      i = i + j\n",
        "    label = label + 1\n",
        "\n",
        "  # Print the precision and recall, among other metrics\n",
        "  print(metrics.classification_report(y_true, y_pred, digits=3))\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGiEou58fwfa",
        "outputId": "2ca12402-ba90-4b4d-ea03-e51ae360926c"
      },
      "source": [
        "acc_mode(clf,X_test_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.486     0.944     0.642        18\n",
            "           1      0.778     0.412     0.538        17\n",
            "           2      0.786     0.611     0.688        18\n",
            "           3      0.800     0.235     0.364        17\n",
            "           4      0.520     0.722     0.605        18\n",
            "\n",
            "    accuracy                          0.591        88\n",
            "   macro avg      0.674     0.585     0.567        88\n",
            "weighted avg      0.671     0.591     0.570        88\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPgNPjzFp8jw"
      },
      "source": [
        "# Compute SVM mean accuracy score regarding whole wav files\n",
        "# NOT USED\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_list = []\n",
        "\n",
        "i = 0\n",
        "for k in test_nframes:\n",
        "  for j in k:\n",
        "    pred = clf.predict(X_test_scaled[i:i+j,:])\n",
        "    acc = accuracy_score(Y_test[i:i+j,],pred,True)\n",
        "    accuracy_list.append(acc)\n",
        "    i = i + j\n",
        "\n",
        "print(\"Mean accuracy: \", np.mean(accuracy_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8AYszUgfAq1"
      },
      "source": [
        "# SVM Classification report framewise\n",
        "# NOT USED\n",
        "from sklearn import metrics\n",
        "pred = clf.predict(X_test_scaled)\n",
        "print(metrics.classification_report(Y_test, pred, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqXa_DqyF2OQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d26d44e-efea-4a1d-b69f-50f318016c26"
      },
      "source": [
        "# Implement Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "clf_lgr = LogisticRegression(C=10,random_state=0,solver='sag',max_iter=50)\n",
        "str = time.time()\n",
        "clf_lgr.fit(X_train_scaled, Y_train)\n",
        "print(\"Log Reg train time\",time.time()-str,\"s\\n\")\n",
        "clf_lgr.predict(X_test_scaled)\n",
        "\n",
        "acc_mode(clf_lgr,X_test_scaled)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log Reg train time 2.384178876876831 s\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.533     0.889     0.667        18\n",
            "           1      0.500     0.118     0.190        17\n",
            "           2      0.526     0.556     0.541        18\n",
            "           3      0.500     0.176     0.261        17\n",
            "           4      0.517     0.833     0.638        18\n",
            "\n",
            "    accuracy                          0.523        88\n",
            "   macro avg      0.515     0.514     0.459        88\n",
            "weighted avg      0.516     0.523     0.465        88\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T0JSpSjZoZU",
        "outputId": "5181400e-5707-4421-f433-f9df7708d71b"
      },
      "source": [
        "# Implement Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtree = DecisionTreeClassifier(criterion='entropy')\n",
        "str = time.time()\n",
        "dtree.fit(X_train_scaled, Y_train)\n",
        "print(\"time: \",time.time()-str)\n",
        "acc_mode(dtree,X_test_scaled)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time:  7.249677896499634\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.548     0.944     0.694        18\n",
            "           1      0.636     0.412     0.500        17\n",
            "           2      0.737     0.778     0.757        18\n",
            "           3      0.667     0.235     0.348        17\n",
            "           4      0.571     0.667     0.615        18\n",
            "\n",
            "    accuracy                          0.614        88\n",
            "   macro avg      0.632     0.607     0.583        88\n",
            "weighted avg      0.631     0.614     0.586        88\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmYlAyov1EXD",
        "outputId": "c267c594-10e9-4618-bac9-9f081b07e5d2"
      },
      "source": [
        "# Implement k-NN\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\r\n",
        "\r\n",
        "knn.fit(X_train_scaled,Y_train)\r\n",
        "\r\n",
        "acc_mode(knn,X_test_scaled)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.531     0.944     0.680        18\n",
            "           1      0.500     0.529     0.514        17\n",
            "           2      0.571     0.667     0.615        18\n",
            "           3      1.000     0.176     0.300        17\n",
            "           4      0.786     0.611     0.688        18\n",
            "\n",
            "    accuracy                          0.591        88\n",
            "   macro avg      0.678     0.586     0.559        88\n",
            "weighted avg      0.676     0.591     0.563        88\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv_NCYsPve0R",
        "outputId": "eb086b43-eb3e-4e31-cdb2-84d83c892793"
      },
      "source": [
        "# Implement ensemble using the above models\r\n",
        "def ensemble_acc(clf,X,Y):\r\n",
        "  accuracy_list = []\r\n",
        "  y_pred = []\r\n",
        "  y_true = []\r\n",
        "\r\n",
        "  i = 0\r\n",
        "  label = 0\r\n",
        "  count = 0\r\n",
        "  for k in test_nframes:\r\n",
        "    for j in k:\r\n",
        "      pred0 = clf[0].predict(X[i:i+j,:])\r\n",
        "      pred1 = clf[1].predict(X[i:i+j,:])\r\n",
        "      pred2 = clf[2].predict(X[i:i+j,:])\r\n",
        "      pred = []\r\n",
        "      for m in range(len(pred0)):\r\n",
        "        try:\r\n",
        "          val = mode([pred0[m],pred1[m],pred2[m]])\r\n",
        "        except:\r\n",
        "          val = pred0[m]\r\n",
        "        pred.append(val)\r\n",
        "      try:\r\n",
        "        val = mode(pred)\r\n",
        "      except:\r\n",
        "        count = count + 1\r\n",
        "        val = round(np.mean(pred))\r\n",
        "      y_pred.append(val)\r\n",
        "      y_true.append(label)\r\n",
        "      i = i + j\r\n",
        "    label = label + 1\r\n",
        "\r\n",
        "  # Print the precision and recall, among other metrics\r\n",
        "  print(metrics.classification_report(y_true, y_pred, digits=3))\r\n",
        "\r\n",
        "ensemble_acc([clf,dtree,knn],X_test_scaled,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.486     0.944     0.642        18\n",
            "           1      0.667     0.353     0.462        17\n",
            "           2      0.706     0.667     0.686        18\n",
            "           3      0.800     0.235     0.364        17\n",
            "           4      0.591     0.722     0.650        18\n",
            "\n",
            "    accuracy                          0.591        88\n",
            "   macro avg      0.650     0.584     0.560        88\n",
            "weighted avg      0.648     0.591     0.564        88\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}